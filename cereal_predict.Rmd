---
title: "R Notebook"
output: html_notebook
---

Let's use a neural network to try to predict product ratings for cereal.

You work for a large breakfast food company. The product development team has asked you to help them try to predict how well their new cereals will sell. They have provided you with product information and ratings for 75 cereals. You can try to solve this with a linear model (linear regression) or you could try a neural network.
For this one, let's try a neural network
```{r echo=FALSE, warning=FALSE}


# Read the Data
data = read.csv("cereals.csv", header=T)

# Random sampling
samplesize = 0.65 * nrow(data)
# this will be a 65/35 split for training/testing data
set.seed(80)
index = sample( seq_len ( nrow ( data ) ), size = samplesize )

# Create training and test set
datatrain = data[ index, ]
datatest = data[ -index, ]
```

The data needs to be normalized for the NN to work correctly. this means that we have to "squash" all of the data, no matter what it is, to be either between 0 and 1 or -1 and 1. There are many ways to do this, here we use min/max
```{r}
## normalize data for neural network

max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
```

```{r}
## Fit neural network 

# load library
library(neuralnet)

# creating training and test set
trainNN = scaled[index , ]
testNN = scaled[-index , ]

# fit neural network
#this line shows that we want to predict rating based on the inputs of cals, protein, fat, sodium and fiber. We will have 3 nodes in the hidden layer and we want linear output (predict between 0 and 1, as opposed to classification, using trainNN as the training data)
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 4 , linear.output = T )
#NN = neuralnet(rating ~ calories  , trainNN, hidden = 2 , linear.output = T )
# plot neural network
#this doesn't do anything other than to show us what the model looks like
plot(NN)

```

Now let's make predictions (remember that the output is normalized, so we have to scale it back)
```{r}
## Prediction using neural network

predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)

plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")

abline(0,1)

# Calculate Root Mean Square Error (RMSE)
RMSE1.NN = (sum((datatest$rating - predict_testNN)^2) / nrow(datatest)) ^ 0.5
```

So, our model is created and trained, we have checked it against test data. let's try to make some predictions on our rating. 
Our new cereal has:
Calories: 90
Protein: 3
Fat: 0
Sodium: 45
Fiber: 4

First build a dataframe with just out new values, rating will be NA, then normalize:
```{r}
newCereal <- data.frame(calories=rep(90,1),protein=rep(3,1),fat=rep(0,1),sodium=rep(45,1),fiber=rep(4,1),rating=rep(NA,1),stringsAsFactors = FALSE)
#we have to normalize these
scaledNew <- as.data.frame(scale(newCereal, center = min, scale = max - min))
```

Make a prediction and then de-normalize it back to a number we expect:
```{r}
newpredict = compute(NN, scaledNew[,c(1:5)])
newpredict = (newpredict$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
newpredict
```
So now you can report back to the product development team what you predict the rating of the cereal will be. 
NOTE: unlike linear regression we don't have confidence intervals to include. What we can do though, is include measures like RMSE. Let's run k-fold cross-validation, get the measure for RMSE and see if our prediction changes:

```{r}

# Load libraries
library(boot)
library(plyr)

# Initialize variables
set.seed(50)
k = 100
RMSE.NN = NULL

List = list( )

# Fit neural network model within nested for loop
for(j in 10:65){
    for (i in 1:k) {
        index = sample(1:nrow(data),j )

        trainNN = scaled[index,]
        testNN = scaled[-index,]
        datatest = data[-index,]

        NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 4, linear.output= T)
        predict_testNN = compute(NN,testNN[,c(1:5)])
        predict_testNN = (predict_testNN$net.result*(max(data$rating)-min(data$rating)))+min(data$rating)

        RMSE.NN [i]<- (sum((datatest$rating - predict_testNN)^2)/nrow(datatest))^0.5
    }
    List[[j]] = RMSE.NN
}

Matrix.RMSE = do.call(cbind, List)
boxplot(Matrix.RMSE[,56], ylab = "RMSE", main = "RMSE BoxPlot (length of traning set = 65)")
```
Make a prediction and then de-normalize it back to a number we expect:
```{r}
newpredict2 = compute(NN, scaledNew[,c(1:5)])
newpredict2 = (newpredict2$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
newpredict2
```

How did our prediction change after running K crossvalidation? Do you think it's a more accurate prediction? why?

Let's look at how RMSE changes with how big the training set is:
```{r}
## Variation of median RMSE 
#install.packages("matrixStats")
library(matrixStats)

med = colMedians(Matrix.RMSE)

X = seq(10,65)

plot (med~X, type = "l", xlab = "size of training set", ylab = "median RMSE", main = "Variation of RMSE with size of training set")
```


